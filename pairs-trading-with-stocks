import pandas as pd
import numpy as np
import datetime as dt
import matplotlib.pyplot as plt
from itertools import combinations
from datetime import datetime, timedelta
import yfinance as yf

# Number of pairs in a portfolio during a period
PORTFOLIO_SIZE = 20
# Load data
data = pd.read_excel("sp500.xlsx", sheet_name="updated")
ind = data[data['date'] == '2000-01-03'].index[0]
data = data.iloc[ind:]
data['date'] = pd.to_datetime(data['date']).apply(lambda x: x.strftime('%Y-%m-%d'))

# Create tickers dictionary
tickers = {data['date'][i]: data['tickers'][i].split(",") for i in range(ind, len(data)+ind)}

month_end_range = pd.date_range('1-Jan-2000','1-Apr-2024', freq='M').strftime("%Y-%m-%d").tolist()
dates_list = list(tickers.keys())

# Collect all tickers
all_tickers = set()
for t in tickers.values():
    all_tickers.update(t)
all_tickers = list(all_tickers)

tickers_to_remove = ['TIE', 'BSC', 'BDK', 'CBE', 'ACS', 'MEE', 'BOL']
filtered_tickers = [ticker for ticker in all_tickers if ticker not in tickers_to_remove]

historical_data = yf.download(filtered_tickers, start="1999-01-01", end="2024-04-01", group_by='ticker')
adj_close_data = historical_data.xs('Adj Close', level=1, axis=1)
# Drop columns where all values are NaN
close_prices = adj_close_data.dropna(axis=1, how='all')


def normalize(df, min_vals, max_vals):
    return (df - min_vals) / (max_vals - min_vals)

def calculate_ssd(df):
    filtered_df = df.dropna(axis=1)
    return {f'{c1}-{c2}': np.sum((filtered_df[c1] - df[c2]) ** 2) for c1, c2 in combinations(filtered_df.columns, 2)}

def top_x_pairs(df, start, end):
    ssd_results_dict = calculate_ssd(df)
    sorted_ssd_dict = dict(sorted(ssd_results_dict.items(), key=lambda item: item[1]))
    most_similar_pairs = {}
    coins = set()
    for pair, ssd in sorted_ssd_dict.items():
        coin1, coin2 = pair.split('-')
        if coin1 not in coins and coin2 not in coins:
            most_similar_pairs[coin1] = (pair, ssd)
            coins.add(coin1)
            coins.add(coin2)
            if len(most_similar_pairs) == PORTFOLIO_SIZE:
                break
      
    sorted_ssd = dict(sorted(most_similar_pairs.items(), key=lambda item: item[1][1]))
    top10_pairs = list(sorted_ssd.values())[:PORTFOLIO_SIZE]
    return top10_pairs

def get_previous_date(dates_list, target_date_str):
    dates = [datetime.strptime(date, '%Y-%m-%d') for date in dates_list]
    target_date = datetime.strptime(target_date_str, '%Y-%m-%d')
    dates.sort()
    previous_date = None
    for date in dates:
        if date >= target_date:
            break
        previous_date = date
    return previous_date.strftime('%Y-%m-%d') if previous_date else None

def one_day_after(date_str):
    date_format = "%Y-%m-%d"
    date_obj = datetime.strptime(date_str, date_format)
    one_day_after = date_obj + timedelta(days=1)
    return one_day_after.strftime(date_format)

def one_year_before(date_str):
    date_format = "%Y-%m-%d"
    original_date = datetime.strptime(date_str, date_format)
    try:
        one_year_before = original_date.replace(year=original_date.year - 1)
    except ValueError:
        one_year_before = original_date.replace(month=2, day=28, year=original_date.year - 1)
    return one_year_before.strftime(date_format)

def pairs_df(formation_data, trading_data, pair_list, threshold=2):
    pairs_dict = {}
    for pair in pair_list:
        asset1, asset2 = pair[0].split('-')
        pairs = pd.DataFrame({
            asset1: trading_data[asset1],
            asset2: trading_data[asset2]
        })
        formation_diff_mean = (formation_data[asset1] - formation_data[asset2]).mean()
        formation_diff_std =  (formation_data[asset1] - formation_data[asset2]).std()
        pairs['diff'] = pairs[asset1] - pairs[asset2]
        pairs['z_score'] = (pairs['diff'] - formation_diff_mean) / formation_diff_std
        z_score = pairs['z_score']

        long_m1 = z_score < -2
        long_m2 = z_score > 0
        long_positions = np.zeros_like(z_score, dtype =bool)
        long_positions[long_m1] = True
        for i in range(1,len(long_positions)):
            if long_positions[i-1]: 
                long_positions[i] = True
            if long_m2[i]:
                long_positions[i] = False
        pairs['long_positions'] = long_positions.astype(int)

        buy = np.zeros_like(z_score, dtype=bool)
        if long_m1[0]:
            buy[0] = 1
        buy[1:] = long_positions[1:] & ~long_positions[:-1]
        #Or sell[1:] = m1[1:] & ~positions[:-1]
        buy = buy.astype(int)
        pairs['buy'] = buy

        long_exit = np.zeros_like(z_score, dtype=bool)
        long_exit[1:] = long_m2[1:] & long_positions[:-1]
        long_exit = long_exit.astype(int)
        pairs['long_exit'] = long_exit


        short_m1 = z_score > 2 
        short_m2 = z_score < 0
        short_positions = np.zeros_like(z_score, dtype =bool)
        short_positions[short_m1] = True
        for i in range(1,len(short_positions)):
            if short_positions[i-1] : 
                short_positions[i] = True
            if short_m2[i] : 
                short_positions[i] = False
        pairs['short_positions'] = short_positions.astype(int)

        sell = np.zeros_like(z_score, dtype=bool)
        if short_m1[0]:
            sell[0] = 1
        sell[1:] = short_positions[1:] & ~short_positions[:-1]
        #Or sell[1:] = m1[1:] & ~positions[:-1]
        sell = sell.astype(int)
        pairs['sell'] = sell

        short_exit = np.zeros_like(z_score, dtype=bool)
        short_exit[1:] = short_m2[1:] & short_positions[:-1]
        short_exit = short_exit.astype(int)
        pairs['short_exit'] = short_exit
        
        pairs['time'] = pairs.index
        pairs.reset_index(drop=True, inplace=True)
        pairs_dict[pair[0]] = pairs
    return pairs_dict

def strategy_return(data, commission = 0.001):
    pnl = 0
    for df in data.values():
        long_entries = df[df['buy'] == 1].index
        short_entries = df[df['sell'] == 1].index
        for idx in long_entries:
            exit_idx = df[(df.index > idx) & (df['long_exit'])].index
            long = df.columns[0]
            short = df.columns[1]
            long_entry_price = close_prices[long][df.loc[idx]['time']] * (1 + commission)
            short_entry_price = close_prices[short][df.loc[idx]['time']] * (1 - commission)
            if not exit_idx.empty:
                long_exit_price = close_prices[long][df.loc[exit_idx[0]]['time']] * (1 - commission)
                short_exit_price = close_prices[short][df.iloc[exit_idx[0]]['time']] * (1 + commission)
                ret = (long_exit_price / long_entry_price - short_exit_price / short_entry_price) / 2
                pnl += ret
            # if there is no mean reversion until the end of period, we close the position.
            else:
                long_exit_price = close_prices[long][df.iloc[-1]['time']] * (1 - commission)
                short_exit_price = close_prices[short][df.iloc[-1]['time']] * (1 + commission)
                ret = (long_exit_price / long_entry_price - short_exit_price / short_entry_price) / 2
                pnl += ret
        for idx in short_entries:
            exit_idx = df[(df.index > idx) & (df['short_exit'])].index
            long = df.columns[1]
            short = df.columns[0]
            long_entry_price = close_prices[long][df.loc[idx]['time']] * (1 + commission)
            short_entry_price = close_prices[short][df.loc[idx]['time']] * (1 - commission)
            if not exit_idx.empty:
                long_exit_price = close_prices[long][df.loc[exit_idx[0]]['time']] * (1 - commission)
                short_exit_price = close_prices[short][df.iloc[exit_idx[0]]['time']] * (1 + commission)
                ret = (long_exit_price / long_entry_price - short_exit_price / short_entry_price) / 2
                pnl += ret
            # if there is no mean reversion until the end of period, we close the position.
            else:
                # short asset1, long asset2 when the position is forcefully closed
                long_exit_price = close_prices[long][df.iloc[-1]['time']] * (1 - commission)
                short_exit_price = close_prices[short][df.iloc[-1]['time']] * (1 + commission)
                ret = (long_exit_price / long_entry_price - short_exit_price / short_entry_price) / 2
                pnl += ret
    return pnl / PORTFOLIO_SIZE

def filter_stocks(date):
    nearest_date = get_previous_date(dates_list, date)
    stock_list = tickers[nearest_date]
    formation_start_date = one_year_before(date)
    stocks_data = historical_data.loc[formation_start_date:date]
    # delete stocks with no data and low liquidity
    adj_close_row = stocks_data.xs('Adj Close', level=1, axis=1)
    nan_columns = adj_close_row.columns[adj_close_row.isna().any()]
    stocks_data_cleaned = stocks_data.drop(columns=nan_columns)
    avg_volume = stocks_data_cleaned.xs('Volume', level=1, axis=1).mean()
    liquid_stocks = avg_volume[avg_volume >= 100000].index
    filtered_stocks = [stock for stock in stock_list if stock in liquid_stocks]
    return filtered_stocks

def calculate_strategy_returns(holding):
    strategy_returns = []
    for i in range(0, len(month_end_range)-holding, holding):
        date = month_end_range[i]
        filtered_stocks = filter_stocks(date)
        end_date = month_end_range[month_end_range.index(date)+holding]
        formation_data = historical_data[filtered_stocks].loc[one_year_before(date):date].xs('Adj Close', level=1, axis=1)
        min_vals = formation_data.min(skipna=True)
        max_vals = formation_data.max(skipna=True)
        normalized_formation_data = normalize(formation_data, min_vals, max_vals)
        trading_start_date = one_day_after(date)
        trading_data = historical_data[filtered_stocks].loc[trading_start_date:end_date].xs('Adj Close', level=1, axis=1)
        normalized_trading_data = normalize(trading_data, min_vals, max_vals)
        topx_pairs_list = top_x_pairs(normalized_formation_data, date, trading_start_date)
        rolling_pairs_dict = pairs_df(normalized_formation_data, normalized_trading_data, topx_pairs_list, threshold=2)
        strategy_returns.append(strategy_return(rolling_pairs_dict))
    return strategy_returns
results = calculate_strategy_returns(6)
    


def annualied_geometric_return(returns): 
    returns = [i + 1 for i in returns]
    cumulative_returns = np.cumprod(returns)
    geometric_return = cumulative_returns[-1] ** (1/len(cumulative_returns)) - 1
    # raise to the power of 2 bc these are semiannual returns
    annualized_return = (1 + geometric_return) ** 2 -1
    return annualized_return
annualized_return = annualied_geometric_return(results)
print("Annual return is " + "{:.2%}".format(annualized_return))



# Plot results
# Ensure month_end_range is a DatetimeIndex
#month_end_range = pd.date_range('1-Mar-2021','1-Jul-2024', freq='3ME').strftime("%Y-%m-%d").tolist()
date_range = pd.date_range(start='2000-07-01', end='2024-03-30', freq='6M')
date_range_index = pd.to_datetime(date_range)

# Create the returns Series
returns = pd.Series(results, index=date_range_index)
cumulative_returns = (1 + returns).cumprod()

plt.figure(figsize=(14, 7))
plt.plot(cumulative_returns, label='Pairs trading')
plt.xlabel('Date')
plt.ylabel('Cumulative Returns')
plt.legend()
plt.title('Pairs Trading Performance')
plt.show()


def calculate_max_drawdown(returns):
    returns = [i+1 for i in returns]
    cumulative_returns = np.cumprod(returns)
    peak = np.maximum.accumulate(cumulative_returns)
    drawdown = (cumulative_returns - peak) / peak
    max_drawdown = np.min(drawdown)
    return max_drawdown
max_drawdown = calculate_max_drawdown(results)
print("Maximum Drawdown:", "{:.2%}".format(max_drawdown))


risk_free_data = yf.download('^IRX', start="2001-07-01", end="2024-01-31")
risk_free_rate = risk_free_data['Adj Close'] / 100
annual_risk_free_rate = risk_free_rate.mean()

def calculate_sharpe_ratio(returns): 
    # this should not be constant but should be calculated from yfinance. Can be taken from bab.py file.
    term_risk_free_rate = (1 + annual_risk_free_rate)**(1/2) - 1
    average_return = np.mean(returns)    
    std_dev_returns = np.std(returns, ddof=1)
    excess_return = average_return - term_risk_free_rate    
    sharpe_ratio = excess_return / std_dev_returns
    return sharpe_ratio
sharpe_ratio = calculate_sharpe_ratio(results)
print(f"Sharpe Ratio: {sharpe_ratio:.4f}")
